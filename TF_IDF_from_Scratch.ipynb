{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GsnogjXUQu1K"
   },
   "source": [
    "# NOTE:\n",
    "\n",
    "1. Please implement the TFIDf function such that for each word in a sentence, its corresponding tfidf value is assigned. Thus a 4 x 6 sized matrix should be returned where the rows represent sentences and the columns represent words. We wish to keep it simple in the beginning.\n",
    "\n",
    "2. In reality the TFIDF function should return a matrix where the rows represent sentences and the columns represent words (ie: Features). Every sentence vector in this matrix will be 'd' dimensional, where d = number of unique words in the corpus (ie: Vocabulary).\n",
    "Every position/cell in a sentence vector correponds to a particular word in the vocabulary. If the word is not present in the current sentence, we assign a value of 0 to that cell, else we assign the TFIDF value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0vrZdUum2xPk"
   },
   "source": [
    "# **Implement TF-IDF from scratch**\n",
    "\n",
    "In this assignment, you will implement TF-IDF vectorization of text from scratch using only Python and inbuilt data structures. You will then verify the correctness of the your implementation using a \"grader\" function/cell (provided by us) which will match your implmentation.\n",
    "\n",
    "The grader fucntion would help you validate the correctness of your code. \n",
    "\n",
    "Please submit the final Colab notebook in the classroom ONLY after you have verified your code using the grader function/cell.\n",
    "\n",
    "**(FAQ) Why bother about implementing a function to compute TF-IDF when it is already available in major libraries?**\n",
    "\n",
    "Ans.\n",
    "1. It helps you improve your coding proficiency.\n",
    "2. It helps you obtain a deeper understanding of the concepts and how it works internally. Knowledge of the internals will also help you debug problems better.\n",
    "3. A lot of product based startups and companies do focus on this in thier interviews to gauge your depth and clarity of understanding along with your programming skills. Hence, most top universities have implementations of some ML algorithms/concepts as mandatory assignments.\n",
    "\n",
    "**NOTE: DO NOT change the \"grader\" functions or code snippets written by us.Please add your code in the suggested locations.**\n",
    "\n",
    "Ethics Code:\n",
    "1. You are welcome to read up online resources to implement the code. \n",
    "2. You can also discuss with your classmates on the implmentation over Slack.\n",
    "3. But, the code you wirte and submit should be yours ONLY. Your code will be compared against other stduents' code and online code snippets to check for plagiarism. If your code is found to be plagiarised, you will be awarded zero-marks for all assignments, which have a 10% wieghtage in the final marks for this course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ZxSRJ4KT3OMw"
   },
   "outputs": [],
   "source": [
    "# Corpus to be used for this assignment\n",
    "\n",
    "corpus = [\n",
    "     'this is the first document mostly',\n",
    "     'this document is the second document',\n",
    "     'and this is the third one',\n",
    "     'is this the first document here',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "aYoKXNsU3nhO"
   },
   "outputs": [],
   "source": [
    "# Please implement this fucntion and write your code wherever asked. Do NOT change the code snippets provided by us.\n",
    "def computeTFIDF (corpus):\n",
    "    \"\"\"Given a list of sentences as \"corpus\", return the TF-IDF vectors for all the \n",
    "  sentences in the corpus as a numpy 2D matrix. \n",
    "  \n",
    "  Each row of the 2D matrix must correspond to one sentence \n",
    "  and each column corresponds to a word in the text corpus. \n",
    "  \n",
    "  Please order the rows in the same order as the \n",
    "  sentences in the input \"corpus\". \n",
    "    \n",
    "  Ignore puncutation symbols like comma, fullstop, \n",
    "  exclamation, question-mark etc from the input corpus.\n",
    "  \n",
    "  For e.g, If the corpus contains sentences with these \n",
    "  9 distinct words, ['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this'], \n",
    "  then the first column of the 2D matrix will correpsond to word \"and\", the second column will \n",
    "  correspond to column \"document\" and so on. \n",
    "  \n",
    "  Write this function using only basic Python code, inbuilt Data Structures and  NumPy ONLY.\n",
    "\n",
    "  Implement the code as optimally as possible using the inbuilt data structures of Python.\n",
    "  \"\"\"\n",
    "\n",
    "  ##############################################################\n",
    "  ####   YOUR CODE BELOW  as per the above instructions #######\n",
    "  ##############################################################\n",
    "# first we will find in how many documents a particular word is occuring\n",
    "# for this we will iterate over each document and create a dictionary of word and binary flag of count\n",
    "    idf = {}\n",
    "\n",
    "    for i in corpus:\n",
    "        uniqueElements = (set(i.split()))\n",
    "        for i in uniqueElements:\n",
    "            # if element is not there in dictionary we will add it for the first occurenece with count as 1\n",
    "            if i not in idf:\n",
    "                idf[i] = 1\n",
    "            # else we will add count of 1 in already available\n",
    "            else:\n",
    "                idf[i] += 1\n",
    "\n",
    "    # Creating list of keys\n",
    "    dict_keys = list(idf.keys())\n",
    "\n",
    "    # length of corpus which will be numerator\n",
    "    len_N = len(corpus)\n",
    "\n",
    "    # calculating idf for each word\n",
    "    for i in dict_keys:\n",
    "        idf[i] = np.log(len_N/idf[i])\n",
    "\n",
    "    #print(idf)\n",
    "    \n",
    "    tf_idf = []\n",
    "\n",
    "    #document_word_count = [Counter(x.split(\" \")) for x in corpus]\n",
    "    \n",
    "    # reference taken from https://colab.research.google.com/drive/10saPk07zWMdFvKR_pMaxJT27Dx9v7wD9?usp=sharing#scrollTo=aYoKXNsU3nhO\n",
    "    for doc in corpus:\n",
    "        doc = list(doc.split())\n",
    "        # counter will help in providing count of each word in given list\n",
    "        document_word_count = Counter(doc)\n",
    "        tf_idf_doc = []\n",
    "       \n",
    "        for i in doc:\n",
    "            termFreq = document_word_count[i]/len(doc)\n",
    "            \n",
    "            #getting idf from idf calculated\n",
    "            idf_word = idf[i]\n",
    "            \n",
    "            #output is expected to be rounded to 2 decimals\n",
    "            tfIdf = round(termFreq*idf_word,2)\n",
    "            \n",
    "            #appending tfidf for word\n",
    "            tf_idf_doc.append(tfIdf)\n",
    "            \n",
    "        #appending tfidf for document\n",
    "        tf_idf.append(tf_idf_doc)\n",
    "\n",
    "    return tf_idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cZ_hmMn92bEe"
   },
   "source": [
    "# Grader Cell\n",
    "Please execute the following Grader cell to verify the correctness of your above implementation. This cell will print \"Success\" if your implmentation of the computeTFIDF() is correct, else, it will print \"Failed\". Make sure you get a \"Success\" before you submit the code in the classroom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZUYmXFjfu53i",
    "outputId": "a5ba688d-3a00-4d8e-a0b5-59f67cd70895"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******** Success ********\n"
     ]
    }
   ],
   "source": [
    "###########################################\n",
    "## GRADER CELL: Do NOT Change this.\n",
    "# This cell will print \"Success\" if your implmentation of the computeTFIDF() is correct.\n",
    "# Else, it will print \"Failed\"\n",
    "###########################################\n",
    "import numpy as np\n",
    "\n",
    "# compute TF-IDF using the computeTFIDF() function\n",
    "X_custom = computeTFIDF(corpus)\n",
    "\n",
    "# Reference grader array - DO NOT MODIFY IT\n",
    "X_grader = np.array(\n",
    "    [[0, 0, 0, 0.12, 0.05, 0.23],\n",
    "     [0, 0.1, 0, 0, 0.23, 0.1],\n",
    "     [0.23, 0, 0, 0, 0.23, 0.23],\n",
    "     [0, 0, 0, 0.12, 0.05, 0.23]]\n",
    "     )\n",
    "\n",
    "# compare X_grader and X_custom\n",
    "comparison = (X_grader == X_custom)\n",
    "isEqual = comparison.all()\n",
    "\n",
    "if isEqual:\n",
    "    print(\"******** Success ********\")\n",
    "else:\n",
    "    print(\"####### Failed #######\")\n",
    "    print(\"\\nX_grader = \\n\\n\", X_grader)\n",
    "    print(\"\\n\",\"*\"*50)\n",
    "    print(\"\\nX_custom = \\n\\n\", X_custom)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "TF-IDF from Scratch Assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
